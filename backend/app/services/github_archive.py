"""
TrueTrend CN - GitHub å¾®åšçƒ­æœå­˜æ¡£è·å–å™¨

ä» justjavac/weibo-trending-hot-search ä»“åº“è·å–å†å²å¾®åšçƒ­æœæ•°æ®
æ•°æ®èŒƒå›´: 2020-11-24 è‡³ä»Š
æ›´æ–°é¢‘ç‡: æ¯å°æ—¶
"""

import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from collections import Counter
import httpx


@dataclass
class HotSearchItem:
    """çƒ­æœæ¡ç›®"""
    title: str
    url: str
    date: str  # YYYY-MM-DD


@dataclass
class YearlyTrendItem:
    """å¹´åº¦çƒ­è¯ç»Ÿè®¡"""
    keyword: str
    total_appearances: int      # æ€»å‡ºç°æ¬¡æ•°
    days_on_list: int          # ä¸Šæ¦œå¤©æ•°
    peak_date: str             # å³°å€¼æ—¥æœŸ
    first_seen: str            # é¦–æ¬¡å‡ºç°
    last_seen: str             # æœ€åå‡ºç°
    avg_appearances_per_day: float
    burst_score: float = 0.0   # çˆ†å‘åº¦åˆ†æ•° (æ–°å¢)
    peak_intensity: int = 0    # å³°å€¼å¼ºåº¦ (å•æ—¥æœ€é«˜å‡ºç°æ¬¡æ•°)


# ============================================================
# é»‘åå•: è¿‡æ»¤æ‰æ¸¸æˆã€ç»¼è‰ºã€ç”µè§†å‰§ã€å¸¸è§„æ ç›®ç­‰æ—¥å¸¸çƒ­æœ
# ============================================================

BLACKLIST_KEYWORDS = {
    # æ¸¸æˆ
    "ç‹è€…è£è€€", "åŸç¥", "ç¬¬äº”äººæ ¼", "é˜´é˜³å¸ˆ", "å’Œå¹³ç²¾è‹±", "è‹±é›„è”ç›Ÿ", "lol",
    "æ‹ä¸æ·±ç©º", "æ‹ä¸åˆ¶ä½œäºº", "å…‰ä¸å¤œä¹‹æ‹", "ä»£å·é¸¢", "æ˜æ—¥æ–¹èˆŸ", "å´©å",
    "æ°¸å¤œæ˜Ÿæ²³", "ä¸–ç•Œä¹‹å¤–", "é€†æ°´å¯’", "å‰‘ç½‘3", "æ¢¦å¹»è¥¿æ¸¸", "å¤©æ¶¯æ˜æœˆåˆ€",
    "è›‹ä»”æ´¾å¯¹", "é‡‘é“²é“²", "äº‘é¡¶ä¹‹å¼ˆ", "ç»åŒºé›¶", "é¸£æ½®", "é»‘ç¥è¯æ‚Ÿç©º",
    
    # ç”µç«èµ›äº‹
    "KPL", "WTT", "CBA", "LPL", "Sèµ›", "MSI", "ä¸–å† ", "æŒ‘æˆ˜è€…æ¯",
    "è‹±è¶…", "è¥¿ç”²", "å¾·ç”²", "æ„ç”²", "æ³•ç”²", "æ¬§å† ", "ä¸­è¶…", "äºšé”¦èµ›",
    "æ¬§æ´²æ¯", "ä¸–ç•Œæ¯", "äºšè¿ä¼š", "å…¨è¿ä¼š",
    
    # ç»¼è‰ºèŠ‚ç›®
    "ä½ å¥½æ˜ŸæœŸå…­", "æŠ«è†æ–©æ£˜", "ä¹˜é£ç ´æµª", "å¥”è·‘å§", "æé™æŒ‘æˆ˜",
    "å¤§ä¾¦æ¢", "èŠ±å„¿ä¸å°‘å¹´", "å‘å¾€çš„ç”Ÿæ´»", "å¿«ä¹å¤§æœ¬è¥", "å¤©å¤©å‘ä¸Š",
    "å£°ç”Ÿä¸æ¯", "æ­Œæ‰‹", "æˆ‘æ˜¯æ­Œæ‰‹", "ä¸­å›½å¥½å£°éŸ³", "åˆ›é€ è¥",
    "é’æ˜¥æœ‰ä½ ", "å¶åƒç»ƒä¹ ç”Ÿ", "ç™»é™†è®¡åˆ’", "ç§åœ°å§", "åŠç†Ÿç”·å¥³",
    
    # ç”µè§†å‰§ (çƒ­æ’­å‰§å 2024-2025)
    "æ˜¥è‰²å¯„æƒ…äºº", "èŠ±é—´ä»¤", "æ‰¿æ¬¢è®°", "æƒœèŠ±èŠ·", "è¾¹æ°´å¾€äº‹", "é”¦ç»£ä¸­å›½å¹´",
    "æ–°ç”Ÿ", "æ˜¥èŠ±ç„°", "å¥½ä¸œè¥¿", "å†°é›ªæ˜¥å¤©", "é•¿ç›¸æ€", "ç¹èŠ±",
    "åº†ä½™å¹´", "ç«ç‘°çš„æ•…äº‹", "å¢¨é›¨äº‘é—´", "åº¦åå¹´", "å°æ—¥å­", "ç‹å¦–å°çº¢å¨˜",
    "å”æœè¯¡äº‹å½•", "è²èŠ±æ¥¼", "ä¸å‡¤è¡Œ", "æŸ³èˆŸè®°", "ä¹å°¾ç‹ä¼ ", "é»˜æ€",
    "äººæ°‘å†›é˜Ÿæ·¬ç«å‘å‰", "æ–‡åŒ–ä¸­å›½å›¢åœ†å¹´", "å°é¾™ç³•",
    # 2025å¹´çƒ­æ’­å‰§
    "ç™½æœˆæ¢µæ˜Ÿ", "ä»™å°æœ‰æ ‘", "ç™½è‰²æ©„æ¦„æ ‘", "å…­å§Šå¦¹", "å€¼å¾—çˆ±", "é›å›æ—¶",
    "å¤©åœ°å‰‘å¿ƒ", "æ•–å…‰", "æ•–ä¸™", "è—•é¥¼", "æ‰«æ¯’é£æš´", "ç››ä¸–å¤©ä¸‹",
    "ä»¥æ³•ä¹‹å", "ä¸€ç¬‘éšæ­Œ", "ä¸´æ±Ÿä»™", "å…¥é’äº‘", "å¾—é—²è°¨åˆ¶", "å‡¡äººæ­Œ",
    "æµªæµªå±±å°å¦–æ€ª", "è¦ä¹…ä¹…çˆ±", "çˆ±ä½ ", "è›‡å°å§", "å°è›‡ç³•",
    # æ›´å¤š2025å‰§é›†
    "éš¾å“„", "èµ´å±±æµ·", "æ£‹å£«", "ä»™é€†", "æ— é™æš–æš–", "å¤§å¥‰æ‰“æ›´äºº",
    "å°„é›•", "çŸ³çŸ¶å¨˜å¨˜", "çº¢æˆ¿å­", "æ¡ƒèŠ±æ˜ æ±Ÿå±±", "å››å–œ", "BèŒ",
    
    # ç”µå½±/åŠ¨ç”»
    "ç–¯ç‹‚åŠ¨ç‰©åŸ", "ç¥¨æˆ¿", "å‘¨å¤„é™¤ä¸‰å®³", "å“ªå’", "çƒ­è¾£æ»šçƒ«",
    
    # æ˜Ÿåº§/æ—¥å¸¸
    "ç™½æ¡ƒæ˜Ÿåº§", "æ˜Ÿåº§", "å¤©æ°”", "å¤©æ°”é¢„æŠ¥", "æ—©å®‰",
    
    # è‚¡å¸‚ (æ¯å¤©éƒ½æœ‰)
    "Aè‚¡", "è‚¡å¸‚", "å¤§ç›˜", "æ¶¨åœ", "è·Œåœ", "é‡‘ä»·",
    
    # å›ºå®šæ ç›®
    "å­¦ä¹ æ–°è¯­", "æ”¹é©", "æ–°æ—¶ä»£", "ç§è—æµªæ¼«", "ä¹é‡ç´«",
    "æ„Ÿæ‚Ÿæ€»ä¹¦è®°", "è¯»æ‡‚å…¨ä¼š", "ä¹ è¿‘å¹³", "æ€»ä¹¦è®°",
    
    # æ‰‹æœº/ç§‘æŠ€äº§å“
    "å°ç±³15", "å°ç±³14", "åä¸º", "iPhone", "Mate",
}

# æ­£åˆ™é»‘åå•: åŒ¹é…ç‰¹å®šæ¨¡å¼
BLACKLIST_PATTERNS = [
    r"^.*vs.*$",                    # å¯¹æˆ˜ç±»æ ‡é¢˜
    r"^è·Ÿç€.*æ¢å¯».*$",              # å›ºå®šæ ç›®
    r"^.*æ‹ç»¼.*$",                  # æ‹çˆ±ç»¼è‰º
    r"^.*æ”¶è§†ç‡.*$",                # æ”¶è§†ç‡ç›¸å…³
    r"^.*é¢„å‘Š.*$",                  # é¢„å‘Šç‰‡
    r"^.*é¦–æ’­.*$",                  # é¦–æ’­ç›¸å…³
    r"^.*å¤§ç»“å±€.*$",                # å¤§ç»“å±€
    r"^.*å®šæ¡£.*$",                  # å®šæ¡£ç›¸å…³
    r"^.*å®˜å®£.*$",                  # å®˜å®£ç›¸å…³  
    r"^ç”µå½±.*$",                    # ç”µå½±å¼€å¤´
    r"^.*ä¹‹è¡Œ$",                    # XXä¹‹è¡Œ
    r"^.*ä¸­å›½å¹´.*$",                # èŠ‚æ—¥æ ç›®
]


def is_blacklisted(keyword: str) -> bool:
    """æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨é»‘åå•ä¸­"""
    import re
    
    # ç²¾ç¡®åŒ¹é…
    keyword_lower = keyword.lower()
    for bl in BLACKLIST_KEYWORDS:
        if bl.lower() in keyword_lower:
            return True
    
    # æ­£åˆ™åŒ¹é…
    for pattern in BLACKLIST_PATTERNS:
        if re.match(pattern, keyword, re.IGNORECASE):
            return True
    
    return False


def calculate_burst_score(
    total_appearances: int,
    days_on_list: int,
    peak_intensity: int,
    lifespan_days: int
) -> float:
    """
    è®¡ç®—çˆ†å‘åº¦åˆ†æ•° - ç”¨äºè¯†åˆ«å¹´åº¦çƒ­ç‚¹äº‹ä»¶
    
    æ ¸å¿ƒé€»è¾‘:
    - çœŸæ­£çš„çƒ­ç‚¹äº‹ä»¶ä¼šè¿ç»­å¤šå¤©é«˜é¢‘å‡ºç°
    - å•æ¬¡ä¸Šæ¦œçš„è¯é¢˜å¯èƒ½åªæ˜¯æ™®é€šæ–°é—»
    - é•¿æœŸæ–­ç»­å‡ºç°çš„è¯é¢˜å¯èƒ½æ˜¯æ¸¸æˆ/ç»¼è‰ºç­‰
    
    å…¬å¼:
    çˆ†å‘åº¦ = (æ€»å‡ºç°æ¬¡æ•° Ã— ä¸Šæ¦œå¤©æ•°æƒé‡) / ç”Ÿå‘½å‘¨æœŸæƒ©ç½š
    
    - ä¸Šæ¦œå¤©æ•°æƒé‡: 3-10å¤©çš„äº‹ä»¶å¾—åˆ†æœ€é«˜
    - ç”Ÿå‘½å‘¨æœŸæƒ©ç½š: è·¨åº¦è¿‡é•¿(>30å¤©)è¯´æ˜æ˜¯æ–­ç»­è¯é¢˜
    """
    import math
    
    if days_on_list == 0:
        return 0.0
    
    # åŸºç¡€åˆ† = æ€»å‡ºç°æ¬¡æ•°
    base_score = total_appearances
    
    # ä¸Šæ¦œå¤©æ•°æƒé‡: 3-10å¤©çš„äº‹ä»¶æœ€å¯èƒ½æ˜¯çƒ­ç‚¹äº‹ä»¶
    # 1å¤©: 0.3, 2å¤©: 0.6, 3-10å¤©: 1.0, >10å¤©: é€’å‡
    if days_on_list == 1:
        days_weight = 0.3
    elif days_on_list == 2:
        days_weight = 0.6
    elif days_on_list <= 10:
        days_weight = 1.0
    else:
        days_weight = 1.0 / math.log(days_on_list, 5)  # è¶…è¿‡10å¤©é€æ¸é™ä½
    
    # é›†ä¸­åº¦æƒé‡: å‡ºç°å¯†é›†ç¨‹åº¦
    concentration = total_appearances / days_on_list
    
    # ç”Ÿå‘½å‘¨æœŸæƒ©ç½š: è·¨åº¦è¶…è¿‡30å¤©çš„è¯é¢˜é™æƒ
    if lifespan_days <= 14:
        lifespan_penalty = 1.0
    elif lifespan_days <= 30:
        lifespan_penalty = 0.8
    elif lifespan_days <= 60:
        lifespan_penalty = 0.5
    else:
        lifespan_penalty = 0.3
    
    # æœ€ç»ˆå¾—åˆ†
    burst_score = base_score * days_weight * concentration * lifespan_penalty
    
    return round(burst_score, 2)


class GitHubArchiveFetcher:
    """
    GitHub å¾®åšçƒ­æœå­˜æ¡£è·å–å™¨
    
    æ•°æ®æº: https://github.com/justjavac/weibo-trending-hot-search
    æ–‡ä»¶è·¯å¾„: /raw/YYYY-MM-DD.json
    """
    
    BASE_URL = "https://raw.githubusercontent.com/justjavac/weibo-trending-hot-search/master/raw"
    
    # æ•°æ®å¯ç”¨çš„æœ€æ—©æ—¥æœŸ
    MIN_DATE = datetime(2020, 11, 24)
    
    def __init__(self):
        self._client: Optional[httpx.AsyncClient] = None
        self._cache: Dict[str, List[Dict]] = {}  # ç®€å•å†…å­˜ç¼“å­˜
    
    async def _get_client(self) -> httpx.AsyncClient:
        """è·å– HTTP å®¢æˆ·ç«¯"""
        if self._client is None or self._client.is_closed:
            self._client = httpx.AsyncClient(
                timeout=30.0,
                follow_redirects=True
            )
        return self._client
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self._client and not self._client.is_closed:
            await self._client.aclose()
            self._client = None
    
    async def fetch_day_data(self, date: str) -> List[HotSearchItem]:
        """
        è·å–å•æ—¥çƒ­æœæ•°æ®
        
        Args:
            date: æ—¥æœŸå­—ç¬¦ä¸² YYYY-MM-DD
            
        Returns:
            çƒ­æœæ¡ç›®åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        if date in self._cache:
            return [HotSearchItem(title=item["title"], url=item["url"], date=date) 
                    for item in self._cache[date]]
        
        client = await self._get_client()
        url = f"{self.BASE_URL}/{date}.json"
        
        try:
            response = await client.get(url)
            
            if response.status_code == 404:
                print(f"[GitHubArchive] {date} æ•°æ®ä¸å­˜åœ¨")
                return []
            
            response.raise_for_status()
            data = response.json()
            
            # ç¼“å­˜æ•°æ®
            self._cache[date] = data
            
            return [HotSearchItem(title=item["title"], url=item["url"], date=date) 
                    for item in data]
            
        except Exception as e:
            print(f"[GitHubArchive] è·å– {date} æ•°æ®å¤±è´¥: {e}")
            return []
    
    async def fetch_date_range(
        self, 
        start_date: str, 
        end_date: str,
        progress_callback: Optional[callable] = None
    ) -> List[HotSearchItem]:
        """
        è·å–æ—¥æœŸèŒƒå›´å†…çš„çƒ­æœæ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ YYYY-MM-DD
            end_date: ç»“æŸæ—¥æœŸ YYYY-MM-DD
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            çƒ­æœæ¡ç›®åˆ—è¡¨
        """
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d")
        
        all_items = []
        current = start
        total_days = (end - start).days + 1
        processed = 0
        
        while current <= end:
            date_str = current.strftime("%Y-%m-%d")
            items = await self.fetch_day_data(date_str)
            all_items.extend(items)
            
            processed += 1
            if progress_callback:
                progress_callback(processed, total_days, date_str)
            
            current += timedelta(days=1)
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            await asyncio.sleep(0.1)
        
        return all_items
    
    async def fetch_month_data(self, year: int, month: int) -> List[HotSearchItem]:
        """
        è·å–æ•´æœˆçƒ­æœæ•°æ®
        """
        start_date = f"{year}-{month:02d}-01"
        
        # è®¡ç®—æœˆæœ«æ—¥æœŸ
        if month == 12:
            end_date = f"{year}-12-31"
        else:
            next_month = datetime(year, month + 1, 1)
            last_day = next_month - timedelta(days=1)
            end_date = last_day.strftime("%Y-%m-%d")
        
        print(f"[GitHubArchive] è·å– {year}å¹´{month}æœˆ æ•°æ®...")
        return await self.fetch_date_range(start_date, end_date)
    
    async def fetch_year_data(self, year: int) -> List[HotSearchItem]:
        """
        è·å–å…¨å¹´çƒ­æœæ•°æ®
        """
        start_date = f"{year}-01-01"
        end_date = f"{year}-12-31"
        
        # ç¡®ä¿ä¸è¶…è¿‡å½“å‰æ—¥æœŸ
        today = datetime.now()
        if datetime.strptime(end_date, "%Y-%m-%d") > today:
            end_date = today.strftime("%Y-%m-%d")
        
        # ç¡®ä¿ä¸æ—©äºæœ€æ—©å¯ç”¨æ—¥æœŸ
        if datetime.strptime(start_date, "%Y-%m-%d") < self.MIN_DATE:
            start_date = self.MIN_DATE.strftime("%Y-%m-%d")
        
        print(f"[GitHubArchive] è·å– {year}å¹´ æ•°æ® ({start_date} ~ {end_date})...")
        
        def progress(current, total, date):
            if current % 30 == 0 or current == total:
                print(f"  è¿›åº¦: {current}/{total} ({date})")
        
        return await self.fetch_date_range(start_date, end_date, progress)
    
    def aggregate_yearly_stats(
        self, 
        items: List[HotSearchItem],
        filter_blacklist: bool = True,
        sort_by: str = "burst"  # "burst" | "total" | "days"
    ) -> List[YearlyTrendItem]:
        """
        ç»Ÿè®¡å¹´åº¦çƒ­è¯æ’è¡Œ
        
        Args:
            items: çƒ­æœæ¡ç›®åˆ—è¡¨
            filter_blacklist: æ˜¯å¦è¿‡æ»¤é»‘åå• (æ¸¸æˆ/ç»¼è‰º/èµ›äº‹ç­‰)
            sort_by: æ’åºæ–¹å¼ - burst(çˆ†å‘åº¦), total(å‡ºç°æ¬¡æ•°), days(ä¸Šæ¦œå¤©æ•°)
            
        Returns:
            å¹´åº¦çƒ­è¯ç»Ÿè®¡åˆ—è¡¨
        """
        from datetime import datetime
        
        # ç»Ÿè®¡æ¯ä¸ªå…³é”®è¯çš„å‡ºç°ä¿¡æ¯
        keyword_stats: Dict[str, Dict] = {}
        
        for item in items:
            keyword = item.title
            date = item.date
            
            # è¿‡æ»¤é»‘åå•
            if filter_blacklist and is_blacklisted(keyword):
                continue
            
            if keyword not in keyword_stats:
                keyword_stats[keyword] = {
                    "total_appearances": 0,
                    "dates": set(),
                    "first_seen": date,
                    "last_seen": date,
                    "date_counts": Counter(),
                }
            
            stats = keyword_stats[keyword]
            stats["total_appearances"] += 1
            stats["dates"].add(date)
            stats["date_counts"][date] += 1
            
            if date < stats["first_seen"]:
                stats["first_seen"] = date
            if date > stats["last_seen"]:
                stats["last_seen"] = date
        
        # ç”Ÿæˆç»Ÿè®¡ç»“æœ
        results = []
        for keyword, stats in keyword_stats.items():
            peak_date, peak_intensity = stats["date_counts"].most_common(1)[0]
            days_on_list = len(stats["dates"])
            
            # è®¡ç®—ç”Ÿå‘½å‘¨æœŸå¤©æ•°
            first_dt = datetime.strptime(stats["first_seen"], "%Y-%m-%d")
            last_dt = datetime.strptime(stats["last_seen"], "%Y-%m-%d")
            lifespan_days = (last_dt - first_dt).days + 1
            
            # è®¡ç®—çˆ†å‘åº¦
            burst_score = calculate_burst_score(
                total_appearances=stats["total_appearances"],
                days_on_list=days_on_list,
                peak_intensity=peak_intensity,
                lifespan_days=lifespan_days
            )
            
            results.append(YearlyTrendItem(
                keyword=keyword,
                total_appearances=stats["total_appearances"],
                days_on_list=days_on_list,
                peak_date=peak_date,
                first_seen=stats["first_seen"],
                last_seen=stats["last_seen"],
                avg_appearances_per_day=round(stats["total_appearances"] / max(days_on_list, 1), 2),
                burst_score=burst_score,
                peak_intensity=peak_intensity,
            ))
        
        # æ ¹æ®æ’åºæ–¹å¼æ’åº
        if sort_by == "burst":
            results.sort(key=lambda x: x.burst_score, reverse=True)
        elif sort_by == "days":
            results.sort(key=lambda x: x.days_on_list, reverse=True)
        else:  # total
            results.sort(key=lambda x: x.total_appearances, reverse=True)
        
        return results


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

async def get_yearly_hot_words(year: int, limit: int = 100) -> Dict[str, Any]:
    """
    è·å–å¹´åº¦çƒ­è¯æ¦œ
    
    Args:
        year: å¹´ä»½
        limit: è¿”å›æ•°é‡é™åˆ¶
        
    Returns:
        å¹´åº¦çƒ­è¯æ•°æ®
    """
    fetcher = GitHubArchiveFetcher()
    
    try:
        # è·å–å…¨å¹´æ•°æ®
        items = await fetcher.fetch_year_data(year)
        
        if not items:
            return {
                "year": year,
                "trends": [],
                "total_count": 0,
                "error": "æ— æ³•è·å–æ•°æ®",
            }
        
        # ç»Ÿè®¡æ’è¡Œ (é»˜è®¤æŒ‰çˆ†å‘åº¦æ’åºï¼Œè¿‡æ»¤æ¸¸æˆç»¼è‰ºç­‰)
        stats = fetcher.aggregate_yearly_stats(items, filter_blacklist=True, sort_by="burst")
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        trends = [
            {
                "keyword": s.keyword,
                "burst_score": s.burst_score,
                "peak_intensity": s.peak_intensity,
                "total_appearances": s.total_appearances,
                "days_on_list": s.days_on_list,
                "peak_date": s.peak_date,
                "first_seen": s.first_seen,
                "last_seen": s.last_seen,
                "avg_appearances_per_day": s.avg_appearances_per_day,
            }
            for s in stats[:limit]
        ]
        
        return {
            "year": year,
            "trends": trends,
            "total_count": len(stats),
            "total_items": len(items),
            "generated_at": datetime.now().isoformat(),
        }
        
    finally:
        await fetcher.close()


async def get_monthly_hot_words(year: int, month: int, limit: int = 50) -> Dict[str, Any]:
    """
    è·å–æœˆåº¦çƒ­è¯æ¦œ
    """
    fetcher = GitHubArchiveFetcher()
    
    try:
        items = await fetcher.fetch_month_data(year, month)
        
        if not items:
            return {
                "year": year,
                "month": month,
                "trends": [],
                "total_count": 0,
            }
        
        stats = fetcher.aggregate_yearly_stats(items)
        
        trends = [
            {
                "keyword": s.keyword,
                "total_appearances": s.total_appearances,
                "days_on_list": s.days_on_list,
                "peak_date": s.peak_date,
            }
            for s in stats[:limit]
        ]
        
        return {
            "year": year,
            "month": month,
            "trends": trends,
            "total_count": len(stats),
            "generated_at": datetime.now().isoformat(),
        }
        
    finally:
        await fetcher.close()


async def get_daily_archive(date: str) -> Dict[str, Any]:
    """
    è·å–å•æ—¥çƒ­æœå­˜æ¡£
    
    Args:
        date: æ—¥æœŸ YYYY-MM-DD
    """
    fetcher = GitHubArchiveFetcher()
    
    try:
        items = await fetcher.fetch_day_data(date)
        
        return {
            "date": date,
            "items": [{"title": item.title, "url": item.url} for item in items],
            "total_count": len(items),
        }
        
    finally:
        await fetcher.close()


# ============================================================
# CLI æµ‹è¯•
# ============================================================

if __name__ == "__main__":
    import sys
    
    async def main():
        if len(sys.argv) < 2:
            print("ç”¨æ³•:")
            print("  python github_archive.py day 2024-01-01")
            print("  python github_archive.py month 2024 1")
            print("  python github_archive.py year 2024")
            return
        
        cmd = sys.argv[1]
        
        if cmd == "day" and len(sys.argv) >= 3:
            date = sys.argv[2]
            result = await get_daily_archive(date)
            print(f"\nğŸ“… {date} çƒ­æœ ({result['total_count']} æ¡):")
            for i, item in enumerate(result["items"][:20], 1):
                print(f"  {i:2}. {item['title']}")
        
        elif cmd == "month" and len(sys.argv) >= 4:
            year = int(sys.argv[2])
            month = int(sys.argv[3])
            result = await get_monthly_hot_words(year, month)
            print(f"\nğŸ“Š {year}å¹´{month}æœˆ çƒ­è¯æ¦œ (Top 20):")
            for i, trend in enumerate(result["trends"][:20], 1):
                print(f"  {i:2}. {trend['keyword']} ({trend['total_appearances']} æ¬¡, {trend['days_on_list']} å¤©)")
        
        elif cmd == "year" and len(sys.argv) >= 3:
            year = int(sys.argv[2])
            result = await get_yearly_hot_words(year, limit=30)
            print(f"\nğŸ† {year}å¹´åº¦çƒ­è¯æ¦œ (Top 30):")
            for i, trend in enumerate(result["trends"][:30], 1):
                print(f"  {i:2}. {trend['keyword']}")
                print(f"      å‡ºç° {trend['total_appearances']} æ¬¡ | ä¸Šæ¦œ {trend['days_on_list']} å¤© | å³°å€¼ {trend['peak_date']}")
        
        else:
            print("æ— æ•ˆå‘½ä»¤")
    
    asyncio.run(main())
